{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reidentification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from locally_binary_pattern import LocalBinaryPatterns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sift_features import SIFTFeatures\n",
    "from skimage.feature import SIFT, match_descriptors, plot_matches\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize, integral_image\n",
    "from skimage import filters\n",
    "from skimage.measure import find_contours\n",
    "from skimage.feature import haar_like_feature, haar_like_feature_coord, draw_haar_like_feature, hog\n",
    "from PIL import ImageOps\n",
    "import dlib\n",
    "import cv2\n",
    "import random\n",
    "from imutils import face_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_features = []\n",
    "clothes_features = []\n",
    "skeleton_features = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    #Face Features \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "    #Clothes Features\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged1 = cv2.Canny(gray, 50, 100)\n",
    "    edged1 = cv2.dilate(edged, None, iterations=1)\n",
    "    edged1 = cv2.erode(edged, None, iterations=1)\n",
    "    cv2.imshow(\"Clothes\", edged)\n",
    "\n",
    "    #Skeleton Features\n",
    "    edged = cv2.Canny(gray, 50, 100)\n",
    "    edged = cv2.dilate(edged, None, iterations=1)\n",
    "    edged = cv2.erode(edged, None, iterations=1)\n",
    "    cv2.imshow(\"Skeleton\", edged)\n",
    "\n",
    "\n",
    "\n",
    "    # crop the face\n",
    "    (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "    face = frame[y:y+h, x:x+w]\n",
    "    cv2.imshow(\"Face\", face)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b16f8645e0a8ba059fefa4e5720c67052a317968572709b4900e431a97bb31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
