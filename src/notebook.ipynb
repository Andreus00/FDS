{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ReID\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We wanted to reidentify a person, given some samples of the dataset. The idea is to learn the main features of the person in order to distinguish him/her from other people.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we did was to import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from load_data import DataLoader\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import config\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from utils import filter_and_split_dataset\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we did was to read the dataset and extract the information that we need in order to recognize people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataLoader()\n",
    "d.read_dataset()\n",
    "d.shuffle_videos()\n",
    "d.display_dataset()\n",
    "\n",
    "metrics = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do was to design the learning setting. The first and easiest idea was to test a variety of classifiers, and see which works better for our features.\n",
    "\n",
    "We tested different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(name, model_skel, model_clothes, model_face, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test):\n",
    "    global metrics\n",
    "    model_skel.fit(X_skel, y_train)\n",
    "    model_clothes.fit(X_clothes, y_train)\n",
    "    model_face.fit(X_face, y_face)\n",
    "\n",
    "\n",
    "    print(\"-\" * 10)\n",
    "    print(\"|\", name, \"|\")\n",
    "    # Test\n",
    "    print(\"-\" * 10)\n",
    "    skel_pred = model_skel.predict(X_skel_test)\n",
    "    print(classification_report(y_test, skel_pred))\n",
    "    print(\"-\" * 10)\n",
    "    clothes_pred = model_clothes.predict(X_clothes_test)\n",
    "    print(classification_report(y_test, clothes_pred))\n",
    "    print(\"-\" * 10)\n",
    "    face_pred = model_face.predict(X_face_test)\n",
    "    print(classification_report(y_face_test, face_pred))\n",
    "\n",
    "    skel_pred_roc = model_skel.predict_proba(X_skel_test)\n",
    "    clothes_pred_roc = model_clothes.predict_proba(X_clothes_test)\n",
    "    face_pred_roc = model_face.predict_proba(X_face_test)\n",
    "\n",
    "    # skplt.metrics.plot_roc(y_test, skel_pred_roc, title= name.split(\"_\")\n",
    "    #                        [-1].split(\".\")[-1] + \" skel\" + \" ROC\", plot_micro=True, plot_macro=True, classes_to_plot=[\n",
    "    #                        0, 1], ax=None, figsize=None)\n",
    "    # plt.show()\n",
    "    # skplt.metrics.plot_roc(y_test, clothes_pred_roc, title= name.split(\"_\")\n",
    "    #                         [-1].split(\".\")[-1] + \" clothes\" + \" ROC\", plot_micro=True, plot_macro=True, classes_to_plot=[\n",
    "    #                         0, 1], ax=None, figsize=None)\n",
    "    # plt.show()\n",
    "    # skplt.metrics.plot_roc(y_face_test, face_pred_roc, title= name.split(\"_\")\n",
    "    #                         [-1].split(\".\")[-1] + \" face\" + \" ROC\", plot_micro=True, plot_macro=True, classes_to_plot=[\n",
    "    #                         0, 1], ax=None, figsize=None)\n",
    "    # plt.show()\n",
    "    \n",
    "\n",
    "    # skplt.metrics.plot_confusion_matrix(\n",
    "    #     y_test, skel_pred, title=name.split(\"_\")[-1].split(\".\")[-1] + \" skel\" + \" Confusion Matrix\", normalize=True)\n",
    "    # plt.show()\n",
    "    # skplt.metrics.plot_confusion_matrix(\n",
    "    #     y_test, clothes_pred, title=name.split(\"_\")[-1].split(\".\")[-1] + \" clothes\" + \" Confusion Matrix\", normalize=True)\n",
    "    # plt.show()\n",
    "    # skplt.metrics.plot_confusion_matrix(\n",
    "    #     y_face_test, face_pred, title=name.split(\"_\")[-1].split(\".\")[-1] + \" face\" + \" Confusion Matrix\", normalize=True)\n",
    "    # plt.show()\n",
    "\n",
    "    metrics.append([name.split(\"_\")[-1].split(\".\")[-1], y_test, y_face_test, skel_pred, clothes_pred, face_pred, skel_pred_roc, clothes_pred_roc, face_pred_roc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(config.SAMPLED_PATH + \"sample_0_X.npy\")\n",
    "y = np.load(config.SAMPLED_PATH + \"sample_0_y.npy\")\n",
    "X_skel, X_clothes, X_face, _, ___, ____, y_train, _____, y_face, ______ = filter_and_split_dataset(X, y)\n",
    "\n",
    "\n",
    "X = np.load(config.SAMPLED_PATH + \"sample_1_X.npy\")\n",
    "y = np.load(config.SAMPLED_PATH + \"sample_1_y.npy\")\n",
    "X_skel_test, X_clothes_test, X_face_test, _, __, ___, y_test, ____, y_face_test, _____ = filter_and_split_dataset(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import DetCurveDisplay, RocCurveDisplay\n",
    "\n",
    "classifiers_skel = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", max_iter=10000),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(C = 1, kernel = \"linear\", degree = 3, gamma = \"auto\", probability = True, tol = 0.001, random_state = 42),\n",
    "}\n",
    "\n",
    "classifiers_clothes = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", max_iter=10000),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(C = 1, kernel = \"linear\", degree = 3, gamma = \"auto\", probability = True, tol = 0.001, random_state = 42),\n",
    "}\n",
    "\n",
    "classifiers_face = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", max_iter=10000),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(C = 1, kernel = \"linear\", degree = 3, gamma = \"auto\", probability = True, tol = 0.001, random_state = 42),\n",
    "}\n",
    "\n",
    "\n",
    "fig, (ax_roc_skel, ax_det_skel, ax_roc_clothes, ax_det_clothes, ax_roc_face, ax_det_face) = plt.subplots(1, 6, figsize=(50, 5))\n",
    "\n",
    "for name, model in classifiers_skel.items():\n",
    "    model.fit(X_skel, y_train)\n",
    "    RocCurveDisplay.from_estimator(model, X_skel_test, y_test, ax=ax_roc_skel, name=name)\n",
    "    DetCurveDisplay.from_estimator(model, X_skel_test, y_test, ax=ax_det_skel, name=name)\n",
    "\n",
    "for name, model in classifiers_clothes.items():\n",
    "    model.fit(X_clothes, y_train)\n",
    "    RocCurveDisplay.from_estimator(model, X_clothes_test, y_test, ax=ax_roc_clothes, name=name)\n",
    "    DetCurveDisplay.from_estimator(model, X_clothes_test, y_test, ax=ax_det_clothes, name=name)\n",
    "\n",
    "for name, model in classifiers_face.items():\n",
    "    model.fit(X_face, y_face)\n",
    "    RocCurveDisplay.from_estimator(model, X_face_test, y_face_test, ax=ax_roc_face, name=name)\n",
    "    DetCurveDisplay.from_estimator(model, X_face_test, y_face_test, ax=ax_det_face, name=name)\n",
    "\n",
    "\n",
    "ax_roc_skel.set_title(\"Receiver Operating Characteristic (ROC) curves - Skeleton\")\n",
    "ax_det_skel.set_title(\"Detection Error Tradeoff (DET) curves - Skeleton\")\n",
    "ax_roc_clothes.set_title(\"Receiver Operating Characteristic (ROC) curves - Clothes\")\n",
    "ax_det_clothes.set_title(\"Detection Error Tradeoff (DET) curves - Clothes\")\n",
    "ax_roc_face.set_title(\"Receiver Operating Characteristic (ROC) curves - Face\")\n",
    "ax_det_face.set_title(\"Detection Error Tradeoff (DET) curves - Face\")\n",
    "\n",
    "\n",
    "ax_roc_skel.grid(linestyle=\"--\")\n",
    "ax_det_skel.grid(linestyle=\"--\")\n",
    "ax_roc_clothes.grid(linestyle=\"--\")\n",
    "ax_det_clothes.grid(linestyle=\"--\")\n",
    "ax_roc_face.grid(linestyle=\"--\")\n",
    "ax_det_face.grid(linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"ROC_DET_curves.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = DecisionTreeClassifier()\n",
    "m2 = DecisionTreeClassifier()\n",
    "m3 = DecisionTreeClassifier()\n",
    "test_model(\"DecisionTreeClassifier\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'random_state': 42}\n",
    "m1 = RandomForestClassifier(criterion ='entropy', max_depth = None, max_features ='sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 200, random_state = 42)\n",
    "m2 = RandomForestClassifier()\n",
    "m3 = RandomForestClassifier()\n",
    "test_model(\"RandomForestClassifier\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = KNeighborsClassifier()\n",
    "m2 = KNeighborsClassifier()\n",
    "m3 = KNeighborsClassifier()\n",
    "test_model(\"KNeighborsClassifier\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = LogisticRegression(solver=\"liblinear\", max_iter=10000)\n",
    "m2 = LogisticRegression(solver=\"liblinear\", max_iter=10000)\n",
    "m3 = LogisticRegression(solver=\"liblinear\", max_iter=10000)\n",
    "test_model(\"LogisticRegression\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test,  X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = GaussianNB()\n",
    "m2 = GaussianNB()\n",
    "m3 = GaussianNB()\n",
    "test_model(\"GaussianNB\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test,  X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skel {'C': 0.5, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
    "#clothes {'C': 0.5, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
    "#face {'C': 0.5, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'rbf', 'random_state': 2}\n",
    "m1 = SVC(C = 1, kernel = \"linear\", degree = 3, gamma = \"auto\", probability = True, tol = 0.001, random_state = 42)\n",
    "m2 = SVC(C = 1, kernel = \"linear\", degree = 3, gamma = \"auto\", probability = True, tol = 0.001, random_state = 42)\n",
    "m3 = SVC(C = 1, kernel = \"rbf\", degree = 3, gamma = \"auto\", probability = True, random_state = 2, decision_function_shape = \"ovo\")\n",
    "test_model(\"SVC\", m1, m2, m3, X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def fit_models(models, X_train, y_train):\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train.ravel())\n",
    "        print(name, 'trained.')\n",
    "    return\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred,zero_division=0))\n",
    "        cv_accuracy = cross_val_score(model, X_test, y_test.ravel(), n_jobs=-1, scoring='accuracy')\n",
    "        cv_f1_macro = cross_val_score(model, X_test, y_test.ravel(), n_jobs=-1, scoring='f1_macro')\n",
    "        print(cross_val_score(model, X_test, y_test, scoring='accuracy'))\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f)\" % (cv_accuracy.mean(), cv_accuracy.std() * 2))\n",
    "        print(cross_val_score(model, X_test, y_test, scoring='f1_macro'))\n",
    "        print(\"f1-score: %0.4f (+/- %0.4f)\" % (cv_f1_macro.mean(), cv_f1_macro.std() * 2))\n",
    "        #plot confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "        print('------------------------------------')\n",
    "    return  \n",
    "\n",
    "def tune_model(model, param_grid, scoring, x_train, y_train, grid_jobs):\n",
    "    print('tuning...')\n",
    "    clf = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, verbose=1, n_jobs=grid_jobs)\n",
    "    clf.fit(x_train, y_train.ravel())\n",
    "    print('done')\n",
    "    print()\n",
    "    print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "    best_params = clf.best_params_.copy()\n",
    "    return best_params\n",
    " \n",
    "\n",
    "\n",
    "SVM_param_grid = {\n",
    "    'C': [0.5, 1],\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'decision_function_shape': ['ovo', 'ovr'],\n",
    "    'random_state': [2,42]\n",
    "}\n",
    "\n",
    "RF_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'random_state': [2,42]\n",
    "}\n",
    "\n",
    "Gauss_param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# best_accuracy_params_skel = tune_model(RandomForestClassifier(), RF_param_grid, 'accuracy', X_skel, y_train, -1)\n",
    "\n",
    "# best_f1macro_params_skel = tune_model(RandomForestClassifier(), RF_param_grid, 'f1_macro',  X_skel, y_train, -1)\n",
    "\n",
    "# best_accuracy_params_clothes = tune_model(RandomForestClassifier(), RF_param_grid, 'accuracy', X_clothes, y_train, -1)\n",
    "\n",
    "# best_f1macro_params_clothes = tune_model(RandomForestClassifier(), RF_param_grid, 'f1_macro',  X_clothes, y_train, -1)\n",
    "\n",
    "best_accuracy_params_skel = tune_model(SVC(), SVM_param_grid, 'accuracy', X_face, y_face, -1)\n",
    "\n",
    "best_f1macro_params_skel = tune_model(SVC(), SVM_param_grid, 'f1_macro',  X_face, y_face, -1)\n",
    "\n",
    "best_accuracy_params_clothes = tune_model(SVC(), SVM_param_grid, 'accuracy', X_face, y_face, -1)\n",
    "\n",
    "best_f1macro_params_clothes = tune_model(SVC(), SVM_param_grid, 'f1_macro',  X_face, y_face, -1)\n",
    "\n",
    "best_accuracy_params_face = tune_model(SVC(), SVM_param_grid, 'accuracy', X_face, y_face, -1)\n",
    "\n",
    "best_f1macro_params_face = tune_model(SVC(), SVM_param_grid, 'f1_macro',  X_face, y_face, -1)\n",
    "\n",
    "\n",
    "\n",
    "tuned_models_skel = {\n",
    "    'RF_Skeleton_accuracy': SVC(**best_accuracy_params_skel),\n",
    "    'RF_Skeleton_f1macro': SVC(**best_f1macro_params_skel)\n",
    "}\n",
    "\n",
    "tuned_models_clothes = {\n",
    "    # 'GNB_accuracy': GaussianNB(**best_accuracy_params_clothes),\n",
    "    # 'GNB_f1macro': GaussianNB(**best_f1macro_params_clothes)\n",
    "    'RF_Clothes_accuracy': SVC(**best_accuracy_params_clothes),\n",
    "    'RF_Clothes_f1macro': SVC(**best_f1macro_params_clothes)\n",
    "}\n",
    "\n",
    "tuned_models_face = {\n",
    "    'SVM_Face_accuracy': SVC(**best_accuracy_params_face),\n",
    "    'SVM_Face_f1macro': SVC(**best_f1macro_params_face)\n",
    "}\n",
    "\n",
    "\n",
    "fit_models(tuned_models_skel, X_skel, y_train)\n",
    "fit_models(tuned_models_clothes, X_clothes, y_train)\n",
    "fit_models(tuned_models_face, X_face, y_face)\n",
    "\n",
    "evaluate_models(tuned_models_skel, X_skel, y_train)\n",
    "evaluate_models(tuned_models_clothes, X_clothes, y_train)\n",
    "evaluate_models(tuned_models_face, X_face, y_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "    # Iterate through each set of data in the list\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_size_inches(18.5, 5)\n",
    "fig.suptitle('ROC Curves for Each Class', fontsize=16)\n",
    "\n",
    "\n",
    "for data in metrics:\n",
    "    # Assign variables to the data in the list\n",
    "    label, y_test, y_face_test, skel_pred_roc, clothes_pred_roc, face_pred_roc = data[0], data[1], data[2], data[6][:, 1], data[7][:, 1], data[8][:, 1]\n",
    "\n",
    "    # Compute the false positive rate and true positive rate for each class\n",
    "    fpr_skel, tpr_skel, thresholds_skel = roc_curve(y_test, skel_pred_roc)\n",
    "    fpr_clothes, tpr_clothes, thresholds_clothes = roc_curve(y_test, clothes_pred_roc)\n",
    "    fpr_face, tpr_face, thresholds_face = roc_curve(y_face_test, face_pred_roc)\n",
    "\n",
    "\n",
    "    # Plot the ROC curve for each class\n",
    "    # fig_skels, ax_skels = plt.subplots()\n",
    "    ax[0].plot(fpr_skel, tpr_skel, label=label + ' skel')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot(fpr_clothes, tpr_clothes, label=label + ' clothes')\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(fpr_face, tpr_face, label=label + ' face')\n",
    "    ax[2].legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "We also thought that it was possible to learn a \"latent space\" that ensambles that person's features. The idea is that a regressor can learn how to optimize the outpot of a linear combination so that features from the person that we want to re-identify will output a low value (0) while the other people will output an higher value (1).\n",
    "\n",
    "Given that, we tested some regressors in order to learn the features of a person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logistic, y_logistc, _ = d.sample_dataset(video=vid, return_images=False)\n",
    "X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test = filter_and_split_dataset(X, y)\n",
    "X_skel_logistic, X_clothes_logistic, X_face_logistic, X_skel_test_logistic, X_clothes_test_logistic, X_face_test_logistic, y_train_logistic, y_test_logistic, y_face_logistic, y_face_test_logistic = filter_and_split_dataset(X_logistic, y_logistc)\n",
    "c_svr = 0\n",
    "\n",
    "def test_regression(name, model_skel, model_clothes, model_face, \n",
    "        X_skel, X_clothes, X_face, X_skel_test, X_clothes_test, X_face_test, y_train, y_test, y_face, y_face_test,\n",
    "        X_skel_logistic, X_clothes_logistic, X_face_logistic, X_skel_test_logistic, X_clothes_test_logistic, X_face_test_logistic, y_train_logistic, y_test_logistic, y_face_logistic, y_face_test_logistic):\n",
    "    model_skel.fit(X_skel, y_train)\n",
    "    model_clothes.fit(X_clothes, y_train)\n",
    "    model_face.fit(X_face, y_face)\n",
    "\n",
    "    # Train the logistic regressor\n",
    "    log_reg_skel, log_reg_clothes, log_reg_face = LogisticRegression(), LogisticRegression(), LogisticRegression()\n",
    "\n",
    "    log_reg_skel.fit(model_skel.predict(X_skel_logistic).reshape(-1, 1), y_train_logistic)\n",
    "    log_reg_clothes.fit(model_clothes.predict(X_clothes_logistic).reshape(-1, 1), y_train_logistic)\n",
    "    log_reg_face.fit(model_face.predict(X_face_logistic).reshape(-1, 1), y_face_logistic)\n",
    "\n",
    "\n",
    "# Test\n",
    "    print(\"-\" * 10)\n",
    "    print(\"|\", name, \"|\")\n",
    "    print(\"-\" * 10)\n",
    "    print(\"| skel |\")\n",
    "    skel_pred = model_skel.predict(X_skel_test)\n",
    "    log_skel_pred = log_reg_skel.predict(skel_pred.reshape(-1, 1))\n",
    "\n",
    "    print(classification_report(y_test, log_skel_pred))\n",
    "    print(mean_absolute_error(y_test, skel_pred))\n",
    "    print(mean_squared_error(y_test, skel_pred))\n",
    "\n",
    "\n",
    "    print(\"| clothes |\")\n",
    "    clotehs_pred = model_clothes.predict(X_clothes_test)\n",
    "    log_clotehs_pred = log_reg_clothes.predict(clotehs_pred.reshape(-1, 1))\n",
    "\n",
    "    print(classification_report(y_test, log_clotehs_pred))\n",
    "    print(mean_absolute_error(y_test, clotehs_pred))\n",
    "    print(mean_squared_error(y_test, clotehs_pred))\n",
    "\n",
    "\n",
    "    print(\"| face |\")\n",
    "    face_pred = model_face.predict(X_face_test)\n",
    "    log_face_pred = log_reg_face.predict(face_pred.reshape(-1, 1))\n",
    "\n",
    "    print(classification_report(y_face_test, log_face_pred))\n",
    "    print(mean_absolute_error(y_face_test, face_pred))\n",
    "    print(mean_squared_error(y_face_test, face_pred))\n",
    "\n",
    "    plt.plot(y_test, clotehs_pred, 'o')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(y_test, skel_pred, 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Pipeline([(\"poly\", PolynomialFeatures()), (\"Regression\", LinearRegression())])\n",
    "m2 = Pipeline([(\"poly\", PolynomialFeatures()), (\"Regression\", LinearRegression())])\n",
    "m3 = Pipeline([(\"poly\", PolynomialFeatures()), (\"Regression\", LinearRegression())])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best paramatri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b369d622223678a177c59fe4340d24ef9e31d9a4f6220fb3cdc831e5545a261b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
